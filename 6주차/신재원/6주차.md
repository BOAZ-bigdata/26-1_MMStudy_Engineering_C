#  큐잉 이론이란?

> 큐잉 이론(Queueing Theory)은 대기열(Queue)에서 발생하는 현상을 수학적으로 분석하는 학문. 1909년 덴마크의 엔지니어 Agner Krarup Erlang이 전화 교환망의 혼잡도를 분석하면서 시작되었다.

백엔드 개발자 입장에서 이 이론이 중요한 이유는 간단하다. 
우리가 매일 다루는 시스템이 전부 큐잉 시스템이기 때문.

- HTTP 요청이 서버에 도착해서 처리되기를 기다리는 것

- DB 커넥션 풀에서 커넥션이 반환되기를 기다리는 것

- Kafka, RabbitMQ 같은 메시지 큐에서 컨슈머를 기다리는 것

이 모든 상황이 큐잉 이론의 적용 대상이다.

# 큐잉 이론의 구성요소

A. 고객 도착시간 간격 분포 (Arrival Time Distribution)

| 기호    | 의미                            |
| ----- | ----------------------------- |
| **M** | 지수분포 (Markovian, Exponential) |
| **D** | 상수 (Deterministic)            |
| **E** | 얼랑분포 (Erlang)                 |
| **G** | 일반분포 (General)                |

B. 서비스 시간 분포 (Service Time Distribution)

| 기호    | 의미   |
| ----- | ---- |
| **M** | 지수분포 |
| **D** | 상수   |
| **E** | 얼랑분포 |
| **G** | 일반분포 |

C. 서버의 수 (Number of Servers)

| 구분                | 의미      |
| ----------------- | ------- |
| **단일 서버 (s = 1)** | 서버 1개   |
| **복수 서버 (s > 1)** | 서버 여러 개 |

D. 서비스 규칙 (Service Discipline)

| 기호       | 의미                             |
| -------- | ------------------------------ |
| **FCFS** | 선착순 (First Come First Served)  |
| **LCFS** | 역선착순 (Last Come First Served)  |
| **SIRO** | 임의순서 (Service In Random Order) |
| **GD**   | 일반적 규칙 (General Discipline)    |
| **PRP**  | 우선순위 규칙 (Priority Rule)        |

E. 시스템 규모 (System Capacity, K)

| 구분         | 의미             |
| ---------- | -------------- |
| **유한 (K)** | 최대 수용 인원 제한 있음 |
| **무한 (∞)** | 수용 인원 제한 없음    |

F. 고객 모집단 크기 (Calling Population, N)

| 구분         | 의미         |
| ---------- | ---------- |
| **유한 (N)** | 고객 수 제한 있음 |
| **무한 (∞)** | 고객 수 무한    |



# 핵심 개념 3가지

## 1. 도착률 (λ, Lambda) — Arrival Rate
단위 시간당 시스템에 들어오는 요청의 수.

예시: 초당 100개의 API 요청이 들어온다 → λ = 100 req/s

## 2. 서비스율 (μ, Mu) — Service Rate
단위 시간당 서버가 처리할 수 있는 요청의 수.

예시: 서버 하나가 초당 80개 요청을 처리한다 → μ = 80 req/s

## 3. 트래픽 강도 (ρ, Rho) — Traffic Intensity (Utilization)
시스템의 부하율을 나타내는 핵심 지표.

```
ρ = λ / μ

ρ < 1: 시스템이 안정적으로 운영됨 (처리 속도 > 유입 속도)
ρ = 1: 한계 상태. 큐가 무한히 증가하기 시작
ρ > 1: 시스템 과부하. 요청이 쌓이고 응답 시간이 폭발적으로 증가
```


⚠️ 실무 팁: ρ가 0.7~0.8을 넘어가면 이미 응답 시간이 눈에 띄게 늘어납니다. 

절대 ρ = 1.0에 맞춰 설계하면 안됨.


## 📐 Little's Law ( 시스템 평균 고객 예측 )

> 시스템 내 평균 고객 수 = 도착률 × 평균 체류시간

> L = λ × W

- 기호의미

L: 시스템 안에 있는 평균 요청 수 (큐 대기 + 처리 중)

λ : 평균 도착률 (req/s)W요청 하나가 시스템에 머무는 평균 시간 (응답 시간)

### Little's Law가 강력한 이유
이 공식은 분포에 관계없이 성립한다. 
요청이 일정하게 들어오든, 폭발적으로 들어오든, 처리 시간이 들쭉날쭉하든 상관없이 안정 상태에서 항상 L = λW가 성립한다.

API 서버를 모니터링하니 다음과 같은 수치가 나왔다고 가정해보자.

- 초당 평균 200개 요청 유입 (λ = 200)

- 평균 응답 시간 0.5초 (W = 0.5s)

L = λ × W = 200 × 0.5 = 100
→ 어느 순간이든 시스템에 평균 100개의 요청이 존재한다.

DB 커넥션 풀 사이즈를 설계할 때 활용할 수 있다. 
쿼리 하나의 평균 실행 시간이 0.1초이고 초당 200개의 DB 쿼리가 발생한다면:
L = 200 × 0.1 = 20

→ 커넥션 풀 사이즈를 최소 20 이상으로 설정해야 큐잉 없이 처리 가능합니다.

###  M/M/1 모델 ( 무작위로 도착 + 무작위 서비스 + 단일 서버 )

표기법 이해: M/M/1이란?
큐잉 모델은 Kendall's Notation으로 표기한다.


- M/M/c 모델: 서버 여러 대일 때의 분석 (로드밸런서 설계에 직결)
- M/G/1 모델: 서비스 시간이 일반 분포일 때 (실제 서버에 더 가까움)

등 존재

A / S / c

M의 뜻
A 도착 과정 Markovian = 포아송 분포 (무작위 도착)

S 서비스 시간 분포 Markovian = 지수 분포 (무작위 처리 시간)

c 서버(처리기) 수 1 = 단일 서버

M/M/1은 요청이 무작위로 도착하고, 처리 시간도 무작위이며, 서버는 1개인 가장 기본적인 모델입니다. 실제 웹 서버 하나의 동작을 근사하기에 적합합니다.

### M/M/1 핵심 공식

ρ = λ / μ 라 할 때:

```
① 평균 큐 대기 시간 (Wq)
Wq = ρ / (μ - λ) = ρ / (μ × (1 - ρ))

② 평균 응답 시간 (W, 대기 + 처리)
W = 1 / (μ - λ)

③ 시스템 내 평균 요청 수 (L)
L = ρ / (1 - ρ)
```

### 수치로 보는 ρ의 영향

| λ (req/s) | ρ    | 평균 응답시간 W (ms) | L (평균 요청 수) |
| --------- | ---- | -------------- | ----------- |
| 50        | 0.5  | 20 ms          | 1           |
| 80        | 0.8  | 50 ms          | 4           |
| 90        | 0.9  | 100 ms         | 9           |
| 95        | 0.95 | 200 ms         | 19          |
| 99        | 0.99 | 1000 ms        | 99          |

ρ가 0.5에서 0.99로 거의 두 배가 됐을 뿐인데, 응답 시간은 50배 폭증했다.
이것이 바로 트래픽이 몰릴 때 서버가 갑자기 느려지는 이유이다.


문제: 현재 API 서버 1대가 평균 처리 시간 10ms(μ = 100 req/s)로 동작하고 있습니다. 평상시 트래픽은 60 req/s인데, 이벤트 시 150 req/s까지 올라갑니다. 서버를 몇 대 준비해야 할까요?
풀이:

이벤트 시 λ = 150, 서버 1대 μ = 100 → ρ = 1.5 → 시스템 불가능, 즉시 과부하
서버 2대 → 총 μ = 200 → ρ = 0.75 → W = 1/(200-150) = 20ms, 안정적
서버 3대 → 총 μ = 300 → ρ = 0.5 → W = 1/(300-150) = 6.7ms, 여유 있음

→ 서버 2대로도 동작하지만, 이벤트 중 트래픽 스파이크를 고려하면 3대가 안전합니다.

🛠️ 실무에서 큐잉 이론 활용하기

1. 스레드 풀 / 커넥션 풀 사이즈 결정
Little's Law로 필요한 최소 스레드 수를 계산한 뒤 여유분(20~30%)을 더합니다.

2. SLO/SLA 설계
"99%의 요청이 200ms 이내 응답" 같은 목표를 설정할 때, M/M/1 모델로 현재 ρ에서 예상 응답 시간 분포를 계산해 가능 여부를 수학적으로 검증할 수 있습니다.

3. 오토스케일링 트리거 설정
단순히 CPU 사용률로 스케일링하는 것보다, ρ(트래픽 강도)를 기준으로 스케일링 트리거를 잡으면 더 정확합니다.

```
ρ > 0.7이 되면 스케일 아웃 트리거
traffic_intensity = current_rps / (max_rps_per_instance * instance_count)
if traffic_intensity > 0.7:
    trigger_scale_out()
4. 메시지 큐 컨슈머 수 결정
Kafka 파티션 컨슈머 수를 설계할 때도 동일하게 적용됩니다.

메시지 발행 속도 λ, 컨슈머 하나의 처리 속도 μ를 측정
ρ < 0.8이 되도록 컨슈머 수 c = ceiling(λ / (μ × 0.8))
```


📝 정리

핵심 내용

트래픽 강도 ρ 

ρ = λ/μ, 반드시 1 미만으로 유지. 0.7~0.8 넘으면 경고

Little's Law

L = λW. 분포 무관하게 성립하는 만능 공식M/M/1단일 서버 기본 모델. ρ가 조금만 올라가도 응답 시간이 폭발적으로 증가

큐잉 이론은 "감"으로 설계하던 것을 수학적 근거를 가진 설계로 바꿔줍니다. 다음 번에 스레드 풀 사이즈나 DB 커넥션 풀을 설정할 때, 한 번쯤 이 공식들을 꺼내보세요.
